# here as 'occupied'
years <- 2001:2012
detections <- rep(NA, length(years))
# if a site was surveyed more than once in a season, just
# take the max count observed -- we aren't going to model
# within-season dynamic occupancy
detections_by_year_sampled <- as.numeric(sapply(
X=unique(unit$year),
FUN=function(year){
max(unit@data[which(unit$year == year), 'count']) > 0
}
))
# substitute NA's with true counts for those years
# that were actually sampled
detections[which(years %in% unique(unit$year))] <-
detections_by_year_sampled
return(matrix(detections, nrow=1))
}
))
# estimate effort per-unit (i.e., number of visits to unit)
effort <- as.vector(
sapply(
samples_within_grid_units,
FUN=function(x) sum(!is.na(x$count))
)
# estimate covariates across the following spatial scales:
# width = 500, 1000, 3200, and 5000
# grass composition (total area)
nass_cdl <- raster::raster("~/Incoming/2012_30m_cdls_lek_study.tif")
nlcd <- raster::raster("~/Incoming/2011_30m_nlcd_lek_study.tif")
nass_grass_values <- c(176,195)
nlcd_grass_values <- c(71)
# climate : precipitation
precipitation <- paste(
"/global_workspace/lpci_lek_activity_modeling_workspace_v.3/Raster",
c(
'prec_01.tif',
'prec_02.tif',
'prec_03.tif',
'prec_04.tif',
'prec_05.tif',
'prec_06.tif',
'prec_07.tif',
'prec_08.tif',
'prec_09.tif',
'prec_10.tif',
'prec_11.tif',
'prec_12.tif'
),
sep="/"
)
# climate : temperature
temperature <- paste(
"/global_workspace/lpci_lek_activity_modeling_workspace_v.3/Raster",
c(
'tavg_01.tif',
'tavg_02.tif',
'tavg_03.tif',
'tavg_04.tif',
'tavg_05.tif',
'tavg_06.tif',
'tavg_07.tif',
'tavg_08.tif',
'tavg_09.tif',
'tavg_10.tif',
'tavg_11.tif',
'tavg_12.tif'
),
sep="/"
)
# topography
topography <- paste(
'/global_workspace/lpci_lek_activity_modeling_workspace_v.3/Raster/',
c(
'elevation.tif',
'elevSd3x3.tif'
),
sep="/"
)
# mesquite 'percent cover' (composition)
mesquite_composition_covariates <- paste(
"/global_workspace/lpci_lek_activity_modeling_workspace_v.3/Raster",
c(
'binary_sum_pixels_500scale.img',
'binary_sum_pixels_1000scale.img',
'binary_sum_pixels_3200scale.img',
'binary_sum_pixels_5000scale.img'
),
sep="/"
)
# mesquite interpatch distance
mesquite_interpatch_distance <- paste(
"/global_workspace/lpci_lek_activity_modeling_workspace_v.3/Raster/",
"mesquite_distance_raster.tif",
sep = ""
)
# anthropogenic disturbance
anthropogenic_disturbance_covariates <- paste(
"/global_workspace/lpci_lek_activity_modeling_workspace_v.3/Raster",
c(
'impact_raster_500scale.img',
'impact_raster_1000scale.img',
'impact_raster_3200scale.img',
'impact_raster_5000scale.img'
),
sep="/"
)
# GRASS COMPOSITION
wafwa_lek_grid_units$nass_grass_comp_500 <- OpenIMBCR::par_calc_stat(
X = OpenIMBCR:::extract_by(
polygon = split(
rgeos::gBuffer(rgeos::gCentroid(wafwa_lek_grid_units, byid=T), byid=T, width = 500),
1:nrow(wafwa_lek_grid_units)
),
r = nass_cdl
),
from = nass_grass_values,
fun = OpenIMBCR:::calc_total_area,
area_of_cell=1
)
# GRASS COMPOSITION
wafwa_lek_grid_units$nass_grass_comp_500 <- OpenIMBCR::par_calc_stat(
X = OpenIMBCR:::extract_by(
polygon = split(
rgeos::gBuffer(rgeos::gCentroid(wafwa_lek_grid_units, byid=T), byid=T, width = 500),
1:nrow(wafwa_lek_grid_units)
),
r = nass_cdl
),
from = nass_grass_values,
fun = OpenIMBCR:::calc_total_area
)
gc()
require(devtools)
install_local("/home/ktaylora/Projects/OpenIMBCR/")
require(raster)
require(rgeos)
require(rgdal)
require(OpenIMBCR)
require(parallel)
split_df <- function(df=NULL, split=0.2){
all_rows <- 1:nrow(df)
# not sampling with replacement here -- though across all iterations
# the effect of sampling after splitting will be similar
holdout_rows <- sample(all_rows, size = floor(nrow(df)*split))
keep_rows <- all_rows[ !(all_rows %in% holdout_rows) ]
return(
list(
training = df[keep_rows,],
testing = df[holdout_rows,]
)
}
k_folds_cross_validation_err_rate <- function(m=NULL, df=NULL, k=2, split=0.2, ntree=NULL){
df <- na.omit(df)
# heurisitc : if a number of trees parameter
# wasn't provided, use sample size as an
# estimator
if(is.null(ntree)){
ntree = round(nrow(df)*(1-split)*0.9)
}
# Grab our formula from our RF object
formula <- paste(as.character(formula(m))[2:3], collapse="~")
results <- do.call(rbind, lapply(
X=1:k,
FUN=function(i){
# Grab our initial data.frame and split accorindly
local_df <- split_df(df, split=split)
# Fit our model
m_rf <- randomForest::randomForest(
formula=formula(formula),
data=local_df$training,
do.trace=F,
importance=F,
ntree=ntree
)
oob_err_rate <- mean(m_rf$err.rate[,1])
holdout_err_rate <- as.numeric(as.character(
predict(m_rf, newdata = local_df$testing)
))
holdout_err_rate <- sum(holdout_err_rate == local_df$testing$binomial) /
nrow(local_df$testing)
# go from % accuracy -> % error
holdout_err_rate <- (1 - holdout_err_rate)
return(data.frame(oob=oob_err_rate, holdout=holdout_err_rate))
}
))
return(results)
}
k_folds_rf_predict <- function(m=NULL, df=NULL, xvar=NULL, xval=NULL, k=2, ntree=NULL){
cl <- parallel::makeCluster(parallel::detectCores()-1)
df <- na.omit(df)
# Grab our formula from our RF object
formula <- paste(as.character(formula(m))[2:3], collapse="~")
# heurisitc : if a number of trees parameter
# wasn't provided, use sample size as an
# estimator
if(is.null(ntree)){
ntree = round(nrow(df)*0.95)
}
parallel::clusterExport(
cl,
varlist = c("formula", "df", "xval", "ntree"),
envir = environment()
)
results <- do.call(rbind, parallel::parLapply(
cl = cl,
X = 1:k,
fun = function(i){
require(randomForest)
# shuffle our input dataset
df <- df[sample(1:nrow(df), size = nrow(df), replace = T),]
# Fit our model
m_rf <- randomForest::randomForest(
formula = formula(formula),
data = df,
do.trace = F,
importance = F,
ntree = ntree
)
# permute predictions across the original training data with a fixed value
# for our x variable of interest
df[,xvar] <- xval
y <- predict(m_rf, newdata=df, type="prob", norm.votes=T)
y <- mean(y[,ncol(y)], na.rm=T) # our last column is our positive occupancy class
return(data.frame(x = xval, y = y))
}
))
parallel::stopCluster(cl); rm(cl); gc();
y_se <- sd(results$y)/sqrt(k)
y_mean <- mean(results$y)
return(data.frame(x=xval, y_mean=y_mean, y_se=y_se))
}
k_folds_2_factor_rf_predict <- function(m=NULL, df=NULL, xvar1=NULL, xval1=NULL, xvar2=NULL, xval2=NULL, k=2, ntree=NULL){
cl <- parallel::makeCluster(parallel::detectCores()-1)
df <- na.omit(df)
# Grab our formula from our RF object
formula <- paste(as.character(formula(m))[2:3], collapse="~")
# heurisitc : if a number of trees parameter
# wasn't provided, use sample size as an
# estimator
if(is.null(ntree)){
ntree = round(nrow(df)*0.95)
}
parallel::clusterExport(
cl,
varlist = c("formula", "df", "xval", "ntree"),
envir = environment()
)
results <- do.call(rbind, parallel::parLapply(
cl = cl,
X = 1:k,
fun = function(i){
require(randomForest)
# Fit our model
m_rf <- randomForest::randomForest(
formula = formula(formula),
data = df,
do.trace = F,
importance = F,
ntree = ntree
)
# permute predictions across the original training data with a fixed value
# for our x variable of interest
df[,xvar] <- xval
y <- predict(m_rf, newdata=df, type="prob", norm.votes=T)
y <- y[,ncol(y)] # our last column is our positive occupancy class
y_se <- sd(y)/sqrt(length(y))
y_mean <- mean(y)
return(data.frame(x = xval, y_mean = y_mean, y_se = y_se))
}
))
parallel::stopCluster(cl); rm(cl); gc();
return(colMeans(results))
}
source_pts <- rgdal::readOGR(
dsn = "/global_workspace/lpci_lek_activity_modeling_workspace_v.3/Study_Boundaries_and_Source_Data",
layer = "original_lpci_lepc_lek_data_c_hagen_filtered",
)
wafwa_lek_grid_units <- rgdal::readOGR(
dsn="/global_workspace/lpci_lek_activity_modeling_workspace_v.3/Study_Boundaries_and_Source_Data",
layer="wafwa_lek_grid_units_sampled"
)
wafwa_lek_grid_units <- spTransform(
wafwa_lek_grid_units,
CRS(projection(source_pts))
)
samples_within_grid_units <- lapply(
split(wafwa_lek_grid_units, 1:nrow(wafwa_lek_grid_units)),
FUN = function(unit){
pts <- source_pts[!is.na(sp::over(source_pts, unit)[,1]),] ;
return(pts)
}
)
# flat binomial for our original lek activity attribution
wafwa_lek_grid_units$binomial <- as.vector(sapply(
samples_within_grid_units,
FUN = function(unit){
# any unit with a positive detection (>0) since 2005 is treated
# here as 'occupied'
response <- as.numeric(any(unit$year >= 2005 & unit$count > 0))
return(response)
}
))
# estimate a detection history over the entire survey period
wafwa_lek_grid_unit_detection_histories <- do.call(rbind, lapply(
samples_within_grid_units,
FUN = function(unit){
# any unit with a positive detection (>0) since 2005 is treated
# here as 'occupied'
years <- 2001:2012
detections <- rep(NA, length(years))
# if a site was surveyed more than once in a season, just
# take the max count observed -- we aren't going to model
# within-season dynamic occupancy
detections_by_year_sampled <- as.numeric(sapply(
X=unique(unit$year),
FUN=function(year){
max(unit@data[which(unit$year == year), 'count']) > 0
}
))
# substitute NA's with true counts for those years
# that were actually sampled
detections[which(years %in% unique(unit$year))] <-
detections_by_year_sampled
return(matrix(detections, nrow=1))
}
))
# estimate effort per-unit (i.e., number of visits to unit)
effort <- as.vector(
sapply(
samples_within_grid_units,
FUN=function(x) sum(!is.na(x$count))
)
# estimate covariates across the following spatial scales:
# width = 500, 1000, 3200, and 5000
# grass composition (total area)
nass_cdl <- raster::raster("~/Incoming/2012_30m_cdls_lek_study.tif")
nlcd <- raster::raster("~/Incoming/2011_30m_nlcd_lek_study.tif")
nass_grass_values <- c(176,195)
nlcd_grass_values <- c(71)
# climate : precipitation
precipitation <- paste(
"/global_workspace/lpci_lek_activity_modeling_workspace_v.3/Raster",
c(
'prec_01.tif',
'prec_02.tif',
'prec_03.tif',
'prec_04.tif',
'prec_05.tif',
'prec_06.tif',
'prec_07.tif',
'prec_08.tif',
'prec_09.tif',
'prec_10.tif',
'prec_11.tif',
'prec_12.tif'
),
sep="/"
)
# climate : temperature
temperature <- paste(
"/global_workspace/lpci_lek_activity_modeling_workspace_v.3/Raster",
c(
'tavg_01.tif',
'tavg_02.tif',
'tavg_03.tif',
'tavg_04.tif',
'tavg_05.tif',
'tavg_06.tif',
'tavg_07.tif',
'tavg_08.tif',
'tavg_09.tif',
'tavg_10.tif',
'tavg_11.tif',
'tavg_12.tif'
),
sep="/"
)
# topography
topography <- paste(
'/global_workspace/lpci_lek_activity_modeling_workspace_v.3/Raster/',
c(
'elevation.tif',
'elevSd3x3.tif'
),
sep="/"
)
# mesquite 'percent cover' (composition)
mesquite_composition_covariates <- paste(
"/global_workspace/lpci_lek_activity_modeling_workspace_v.3/Raster",
c(
'binary_sum_pixels_500scale.img',
'binary_sum_pixels_1000scale.img',
'binary_sum_pixels_3200scale.img',
'binary_sum_pixels_5000scale.img'
),
sep="/"
)
# mesquite interpatch distance
mesquite_interpatch_distance <- paste(
"/global_workspace/lpci_lek_activity_modeling_workspace_v.3/Raster/",
"mesquite_distance_raster.tif",
sep = ""
)
# anthropogenic disturbance
anthropogenic_disturbance_covariates <- paste(
"/global_workspace/lpci_lek_activity_modeling_workspace_v.3/Raster",
c(
'impact_raster_500scale.img',
'impact_raster_1000scale.img',
'impact_raster_3200scale.img',
'impact_raster_5000scale.img'
),
sep="/"
)
# GRASS COMPOSITION
wafwa_lek_grid_units$nass_grass_comp_500 <- OpenIMBCR::par_calc_stat(
X = OpenIMBCR:::extract_by(
polygon = split(
rgeos::gBuffer(rgeos::gCentroid(wafwa_lek_grid_units, byid=T), byid=T, width = 500),
1:nrow(wafwa_lek_grid_units)
),
r = nass_cdl
),
from = nass_grass_values,
fun = OpenIMBCR:::calc_total_area
)
install.packages(c("BradleyTerry2", "dtplyr", "Ecfun", "forge", "ggthemes", "haven", "ks", "labelled", "rgeos", "sampleSelection", "sf", "stars"), lib="/usr/lib/R/library")
install.packages("yaml")
require(devtools)
setwd("/home/ktaylora/Projects/OpenIMBCR/")
document()
install.packages('codetools')
document()
install_local(".")
install_local(".", force=T)
require(OpenIMBCR)
units <- readOGR("/home/ktaylora/Incoming/matador_wma_work/vector/","matador_1km_usng_units")
units <- rgdal::readOGR("/home/ktaylora/Incoming/matador_wma_work/vector/","matador_1km_usng_units")
test <- OpenIMBCR::generate_fishnet_grid(units, res=250)
generate_fishnet_grid
detach("OpenIMBCR", unload=T)
detach("package:OpenIMBCR", unload=T)
document()
install_local("/home/ktaylora/Projects/OpenIMBCR/")
install_local("/home/ktaylora/Projects/OpenIMBCR/", force=T)
test <- OpenIMBCR::generate_fishnet_grid(units, res=250)
OpenIMBCR::generate_fishnet_grid
test <- OpenIMBCR::generate_fishnet_grid(units, res=250)
detach("package:OpenIMBCR", unload=T)
install_local("/home/ktaylora/Projects/OpenIMBCR/", force=T)
test <- OpenIMBCR::generate_fishnet_grid(units, res=250)
require(OpenIMBCR)
test <- OpenIMBCR::generate_fishnet_grid(units, res=250)
test <- generate_fishnet_grid(units, res=250)
units
original <- units
class(units)
if(class(units) != "list"){
units <- split(units, 1:nrow(units))
}
split(units, 1:nrow(units))
split(units, 1:nrow(units@data))
units
length(units@polygons)
1:length(units@polygons)
split(units, 1:length(units@polygons))
units
require(rgdal)
split(units, 1:length(units@polygons))
require(sp)
if(class(units) != "list"){
units <- split(units, 1:nrow(units))
}
units
grid <- do.call(
rbind,
lapply(
,
FUN=function(x) OpenIMBCR:::polygon_to_fishnet_grid(x, res=res)
)
grid <- do.call(
rbind,
lapply(
units,
FUN=function(x) OpenIMBCR:::polygon_to_fishnet_grid(x, res=res)
)
res=250
grid <- do.call(
rbind,
lapply(
units,
FUN=function(x) OpenIMBCR:::polygon_to_fishnet_grid(x, res=res)
)
require(sf)
grid <- do.call(
rbind,
lapply(
units,
FUN=function(x) OpenIMBCR:::polygon_to_fishnet_grid(x, res=res)
)
for(i in 1:length(grid@polygons)) {
slot(grid@polygons[[i]], "ID") <- as.character(i)
}
out=SpatialPolygonsDataFrame(grid, data=data.frame(id=1:length(grid@polygons)))
print(out)
plot(out)
document()
install_local("/home/ktaylora/Projects/OpenIMBCR/", force=T)
detach("package:OpenIMBCR", unload=T)
document()
install_local("/home/ktaylora/Projects/OpenIMBCR/", force=T)
